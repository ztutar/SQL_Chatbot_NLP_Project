{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit langchain_core langchain_community ollama\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "onPbOp5CeQc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import ollama as Ollama\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.pool import StaticPool\n",
        "import sqlite3"
      ],
      "metadata": {
        "id": "YSFpGOeII8RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh # download ollama api\n",
        "clear_output()\n",
        "\n",
        "#Create a Python script to start the Ollama API server in a seperate thread\n",
        "\n",
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def ollama():\n",
        "  os.environ['OLLAMA_HOST'] = '127.0.0.1:11434'\n",
        "  os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "  subprocess.Popen(['ollama', 'serve'])"
      ],
      "metadata": {
        "id": "uWDTIp98bnR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()"
      ],
      "metadata": {
        "id": "VrLB3Fj2wXuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull llama3.1:70b\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "cqot1txmtzVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull llama3.1:8b\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "__l3dh04_VXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def connectDatabase(url):\n",
        "    response = requests.get(url)\n",
        "    sql_script = response.text\n",
        "\n",
        "    connection = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
        "    connection.executescript(sql_script)\n",
        "    engine = create_engine(\n",
        "        \"sqlite://\",\n",
        "        creator=lambda: connection,\n",
        "        poolclass=StaticPool,\n",
        "        connect_args={\"check_same_thread\": False})\n",
        "    st.session_state.db = SQLDatabase(engine)\n",
        "\n",
        "def runQuery(query):\n",
        "  if st.session_state.db:\n",
        "    return st.session_state.db.run(query)\n",
        "  else:\n",
        "    \"Please connect to database\"\n",
        "\n",
        "\n",
        "def getDatabaseSchema():\n",
        "  if st.session_state.db:\n",
        "    return st.session_state.db.get_table_info()\n",
        "  else:\n",
        "    \"Please connect to database\"\n",
        "\n",
        "\n",
        "def getQueryFromLLM(llm, question, max_iteration=10):\n",
        "    template = \"\"\"below is the schema of SQLite database, read the schema carefully about the table and column names. Also take care of table or column name case sensitivity.\n",
        "    Finally answer user's question in the form of SQL query.\n",
        "\n",
        "    {schema}\n",
        "\n",
        "    please only provide the SQL query and nothing else\n",
        "\n",
        "    for example:\n",
        "    question: how many albums we have in database\n",
        "    SQL query: SELECT COUNT(*) FROM album\n",
        "    question: how many customers are from Brazil in the database ?\n",
        "    SQL query: SELECT COUNT(*) FROM customer WHERE country=Brazil\n",
        "\n",
        "    your turn :\n",
        "    question: {question}\n",
        "    SQL query :\n",
        "    please only provide the SQL query and nothing else\n",
        "    \"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(template)  # Define prompt outside the loop\n",
        "    chain = prompt | llm  # Define initial chain outside the loop\n",
        "    i = max_iteration\n",
        "    response = None  # Initialize response to None\n",
        "\n",
        "    while i>0:\n",
        "        try:\n",
        "            response = chain.invoke({\n",
        "                \"question\": question,\n",
        "                \"schema\": getDatabaseSchema(),\n",
        "                \"error\" : \"\"\n",
        "            })\n",
        "            # Attempt to execute the query to check its validity\n",
        "            result = runQuery(response.content)\n",
        "            # If execution is successful, break the loop\n",
        "            break\n",
        "        except Exception as error:\n",
        "            # If an error occurs, feed the error message back to the LLM\n",
        "            print(f\"Error encountered: {error}\")\n",
        "            template = \"\"\"Previous query attempt failed with error: {error}.\n",
        "                           Please try generating a different SQL query for the question: {question}.\n",
        "                           Here is the database schema for reference: {schema}\n",
        "                           SQL query: \"\"\"\n",
        "            prompt = ChatPromptTemplate.from_template(template)\n",
        "            chain = prompt | llm\n",
        "            response = chain.invoke({  # Invoke the chain with the error message\n",
        "                \"question\": question,\n",
        "                \"schema\": getDatabaseSchema(),\n",
        "                \"error\": str(error)  # Pass the error message to the prompt\n",
        "            })\n",
        "            i -= 1\n",
        "\n",
        "    if response:  # Check if response has been assigned a value\n",
        "      # Check if the response indicates failure\n",
        "      if \"Failed to generate a valid query.\" in response.content:\n",
        "        return None  # Return None to signal query generation failure\n",
        "      else:\n",
        "        return response.content\n",
        "    else:\n",
        "        return None  # Return None if no response was generated\n",
        "\n",
        "\n",
        "def getResponseForQueryResult(llm, question, query, result):\n",
        "    template2 = \"\"\"below is the schema of SQLite database, read the schema carefully about the table and column names of each table.\n",
        "    Also look into the conversation if available\n",
        "    Finally write a response in natural language by looking into the conversation and result.\n",
        "\n",
        "    {schema}\n",
        "\n",
        "    Here are some example for you:\n",
        "    question: how many albums we have in database\n",
        "    SQL query: SELECT COUNT(*) FROM album;\n",
        "    Result : [(34,)]\n",
        "    Response: There are 34 albums in the database.\n",
        "\n",
        "    question: how many users we have in database\n",
        "    SQL query: SELECT COUNT(*) FROM customer;\n",
        "    Result : [(59,)]\n",
        "    Response: There are 59 users in the database.\n",
        "\n",
        "    question: how many users above are from india we have in database\n",
        "    SQL query: SELECT COUNT(*) FROM customer WHERE country=india;\n",
        "    Result : [(4,)]\n",
        "    Response: There are 4 users in the database.\n",
        "\n",
        "    your turn to write response in natural language from the given result :\n",
        "    question: {question}\n",
        "    SQL query : {query}\n",
        "    Result : {result}\n",
        "    Response:\n",
        "    \"\"\"\n",
        "\n",
        "    prompt2 = ChatPromptTemplate.from_template(template2)\n",
        "    chain2 = prompt2 | llm\n",
        "\n",
        "    response = chain2.invoke({\n",
        "        \"question\": question,\n",
        "        \"schema\": getDatabaseSchema(),\n",
        "        \"query\": query,\n",
        "        \"result\": result\n",
        "    })\n",
        "\n",
        "    return response.content"
      ],
      "metadata": {
        "id": "tIQO8-IkIzAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st.set_page_config(\n",
        "    page_icon=\"ðŸ¤–\",\n",
        "    page_title=\"Chat with SQL DB\",\n",
        "    layout=\"centered\"\n",
        ")\n",
        "st.title(\"Chat with SQL DB  ðŸ¤–\")\n",
        "\n",
        "question = st.chat_input('Chat with an SQL database')\n",
        "\n",
        "if \"chat\" not in st.session_state or st.sidebar.button(\"Clear message history\"):\n",
        "    st.session_state[\"chat\"] = [{\"role\": \"assistant\", \"content\": \"This is a SQL Database Chain that can answer questions about a database. \\\n",
        "        Please input your question below:\"}]\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for chat in st.session_state.chat:\n",
        "    st.chat_message(chat['role']).markdown(chat['content'])\n",
        "\n",
        "models = [model[\"name\"] for model in Ollama.list()[\"models\"]]\n",
        "with st.sidebar:\n",
        "    st.title('Connect to a Database & Select an LLM')\n",
        "    st.text_input(label=\"Database\", key=\"database\", value=\"ex: https://raw.githubusercontent.com/....sql\")\n",
        "    st.sidebar.selectbox(label =\"Model\", key=\"model\", options=models)\n",
        "    connectBtn = st.button(\"Connect\")\n",
        "\n",
        "if connectBtn:\n",
        "    connectDatabase(url=st.session_state.database)\n",
        "    llm = ChatOllama(model=st.session_state.model, temperature=0.1)\n",
        "    st.success(\"Database connected\")\n",
        "\n",
        "if question:\n",
        "    if \"db\" not in st.session_state:\n",
        "        st.error('Please connect to a database first.')\n",
        "    else:\n",
        "        st.session_state.chat.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": question\n",
        "        })\n",
        "\n",
        "        query = getQueryFromLLM(llm, question)\n",
        "        print(query)\n",
        "        result = runQuery(query)\n",
        "        print(result)\n",
        "        response = getResponseForQueryResult(llm, question, query, result)\n",
        "        st.session_state.chat.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": response\n",
        "        })"
      ],
      "metadata": {
        "id": "LpoUAMclRjBU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}